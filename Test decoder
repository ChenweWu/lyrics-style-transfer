{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Test decoder","provenance":[{"file_id":"1Gkr0HpRzMimdHtA4svQt_yC2RQSvjv6F","timestamp":1636350086783},{"file_id":"1H2uLOCobfPt4QeCv1FzHjEhNFQN24LFE","timestamp":1636331624629}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"O1sZWY-sCsSr"},"source":["# Data Loader"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a3z8V6MKkllF","executionInfo":{"status":"ok","timestamp":1636733702156,"user_tz":300,"elapsed":6658,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}},"outputId":"dcb72fd8-09b8-445a-f630-cea573b1469e"},"source":["!pip install unidecode"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting unidecode\n","  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n","\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 5.5 MB/s \n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.3.2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AdPamBGAjCV8","executionInfo":{"status":"ok","timestamp":1636733703834,"user_tz":300,"elapsed":1681,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}},"outputId":"2b723a67-88db-4690-a568-5819c97fa756"},"source":["import json\n","import re\n","from unidecode import unidecode\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","import nltk\n","nltk.download('punkt')\n","from collections import Counter"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k8kZ4Arokgqt","executionInfo":{"status":"ok","timestamp":1636733727995,"user_tz":300,"elapsed":18503,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}},"outputId":"7934dfe4-43c2-4b48-c723-5e2e4ab10e94"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"DYSUIT2PjCWC"},"source":["f = open('/content/drive/Shareddrives/MIT NLP 8.864/Data/drake.json')\n","drake = json.load(f)\n","f.close()\n","\n","f = open('/content/drive/Shareddrives/MIT NLP 8.864/Data/tswift.json')\n","taylor = json.load(f)\n","f.close()\n","\n","drake = [drake['songs'][i]['lyrics'] for i in range(len(drake['songs']))]\n","taylor = [taylor['songs'][i]['lyrics'] for i in range(len(taylor['songs']))]\n","\n","taylor_lyrics = [re.sub('\\u2005', ' ', re.sub(r'[\\(\\[].*?[\\)\\]]', '', taylor[i])).split('\\n') for i in range(len(taylor))]\n","taylor_lyrics = [[unidecode(i) for i in taylor_lyrics[j]] for j in range(len(taylor_lyrics))]\n","taylor_lyrics = [[re.sub('\\d+EmbedShare URLCopyEmbedCopy', '', i) for i in taylor_lyrics[j]] for j in range(len(taylor_lyrics))]\n","taylor_lyrics = [[re.sub('\\d+.EmbedShare URLCopyEmbedCopy', '', i) for i in taylor_lyrics[j]] for j in range(len(taylor_lyrics))]\n","taylor_lyrics = [[re.sub('EmbedShare URLCopyEmbedCopy', '', i) for i in taylor_lyrics[j]] for j in range(len(taylor_lyrics))]\n","taylor_lyrics = [[i for i in taylor_lyrics[j] if i != ''] for j in range(len(taylor_lyrics))]\n","\n","drake_lyrics = [re.sub('\\u2005', ' ', re.sub(r'[\\(\\[].*?[\\)\\]]', '', drake[i])).split('\\n') for i in range(len(drake))]\n","drake_lyrics = [[unidecode(i) for i in drake_lyrics[j]] for j in range(len(drake_lyrics))]\n","drake_lyrics = [[re.sub('\\d+EmbedShare URLCopyEmbedCopy', '', i) for i in drake_lyrics[j]] for j in range(len(drake_lyrics))]\n","drake_lyrics = [[re.sub('\\d+.EmbedShare URLCopyEmbedCopy', '', i) for i in drake_lyrics[j]] for j in range(len(drake_lyrics))]\n","drake_lyrics = [[re.sub('EmbedShare URLCopyEmbedCopy', '', i) for i in drake_lyrics[j]] for j in range(len(drake_lyrics))]\n","drake_lyrics = [[i for i in drake_lyrics[j] if i != ''] for j in range(len(drake_lyrics))]\n","\n","taylor_lyrics = [[line1 + ', ' + line2 for line1,line2 in zip(song[0::2], song[1::2])] for song in taylor_lyrics]\n","taylor_lyrics = [[line1 + ', ' + line2 for line1,line2 in zip(song[0::2], song[1::2])] for song in taylor_lyrics]\n","\n","drake_tokenized = [[word_tokenize(drake_lyrics[i][j]) for j in range(len(drake_lyrics[i]))] for i in range(len(drake_lyrics))]\n","taylor_tokenized = [[word_tokenize(taylor_lyrics[i][j]) for j in range(len(taylor_lyrics[i]))] for i in range(len(taylor_lyrics))]\n","\n","drake_tokenized = [[[word.lower() for word in line] for line in song] for song in drake_tokenized]\n","taylor_tokenized = [[[word.lower() for word in line] for line in song] for song in taylor_tokenized]\n","\n","drake_length = sum([[len(sent) for sent in song] for song in drake_tokenized], [])\n","taylor_length = sum([[len(sent) for sent in song] for song in taylor_tokenized], [])\n","\n","drake_lyrics = sum([[sent for sent in song if (len(sent) >= 10 and len (sent) <= 30)] for song in drake_tokenized], [])\n","taylor_lyrics = sum([[sent for sent in song if (len(sent) >= 10 and len (sent) <= 30)] for song in taylor_tokenized], [])\n","\n","taylor_vocab = sum(taylor_lyrics,[])\n","drake_vocab = sum(drake_lyrics,[])\n","\n","def unique(list1):\n","     \n","    # insert the list to the set\n","    list_set = set(list1)\n","    # convert the set to the list\n","    unique_list = (list(list_set))\n","    return unique_list\n","\n","vocab = taylor_vocab + drake_vocab\n","vocab_counts = Counter(vocab)\n","vocab = unique(vocab)\n","vocab = ['<pad>','<unk>','<s>', '</s>'] + vocab\n","\n","from torch.utils import data\n","import torch\n","\n","# These IDs are reserved.\n","MAX_SENT_LENGTH = 30\n","MAX_SENT_LENGTH_PLUS_SOS_EOS = 32\n","PAD_INDEX = 0\n","UNK_INDEX = 1\n","SOS_INDEX = 2\n","EOS_INDEX = 3\n","RARE_WORD_TRESHOLD = 0\n","\n","vocab_counts['<pad>'] = RARE_WORD_TRESHOLD + 1\n","vocab_counts['<unk>'] = RARE_WORD_TRESHOLD + 1\n","vocab_counts['<s>'] = RARE_WORD_TRESHOLD + 1\n","vocab_counts['</s>'] = RARE_WORD_TRESHOLD + 1\n","\n","class TSTDataset(data.Dataset):\n","    def __init__(self, taylor_sentences, drake_sentences, vocab, vocab_counts, sampling=1.):\n","        self.taylor_sentences = taylor_sentences[:int(len(taylor_sentences) * sampling)]\n","        self.drake_sentences = drake_sentences[:int(len(drake_sentences) * sampling)]\n","\n","        self.max_seq_length = MAX_SENT_LENGTH_PLUS_SOS_EOS\n","        self.vocab = vocab\n","        self.vocab_counts = vocab_counts\n","\n","        self.v2id = {v : i for i, v in enumerate(self.vocab)}\n","        self.id2v = {val : key for key, val in self.v2id.items()}\n","    \n","    def __len__(self):\n","        return min(len(self.taylor_sentences), len(self.drake_sentences))\n","    \n","    def __getitem__(self, index):\n","        taylor_sent = self.taylor_sentences[index]\n","        taylor_len = len(taylor_sent) + 2   # add <s> and </s> to each sentence\n","        taylor_id = []\n","        for w in taylor_sent:\n","            if w not in self.vocab:\n","                w = '<unk>'\n","            if vocab_counts[w] <= RARE_WORD_TRESHOLD:\n","                w = '<unk>'\n","            taylor_id.append(self.v2id[w])\n","\n","        taylor_id = ([SOS_INDEX] + taylor_id + [EOS_INDEX] + [PAD_INDEX] *\n","                  (self.max_seq_length - taylor_len))\n","\n","        drake_sent = self.drake_sentences[index]\n","        drake_len = len(drake_sent) + 2   # add <s> and </s> to each sentence\n","        drake_id = []\n","        for w in drake_sent:\n","            if w not in self.vocab:\n","                w = '<unk>'\n","            if vocab_counts[w] <= RARE_WORD_TRESHOLD:\n","                w = '<unk>'\n","            drake_id.append(self.v2id[w])\n","\n","        drake_id = ([SOS_INDEX] + drake_id + [EOS_INDEX] + [PAD_INDEX] *\n","                  (self.max_seq_length - drake_len))\n","\n","        return torch.tensor(taylor_id), taylor_len, torch.tensor(drake_id), drake_len\n","\n","dataset = TSTDataset(taylor_lyrics, drake_lyrics, vocab, vocab_counts)\n","data_loader = data.DataLoader(dataset, batch_size=2, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ysnDBkXbl-73","executionInfo":{"status":"ok","timestamp":1636733784854,"user_tz":300,"elapsed":130,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}},"outputId":"1a7bb7fb-590d-4549-9b6c-5db333070e0a"},"source":["for a,b,c,d in data_loader:\n","    print(a)\n","    print([' '.join([dataset.id2v[word] for word in line]) for line in a.tolist()])\n","    print(c)\n","    print([' '.join([dataset.id2v[word] for word in line]) for line in c.tolist()])\n","    break"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[   2, 3350,  932, 7838, 2907, 3575, 5624, 8995, 5234, 6444,  932, 2403,\n","          459, 7800, 5624, 5573, 7533, 8349, 1079, 3200,  928, 5624, 5573,  581,\n","          459, 5097, 2029, 3166, 6857, 5713,    3,    0],\n","        [   2, 4904, 5624, 2705, 5624, 5573, 5522,  459, 8685, 6003, 9228, 6761,\n","         5624, 5573, 5522,  459, 8685, 6003, 9228, 3806, 5624, 8512, 5082, 5573,\n","         3850, 5818,    3,    0,    0,    0,    0,    0]])\n","[\"<s> when i passed your house , it 's like i could n't breathe , you heard the rumors from inez , you ca n't believe a word she says </s> <pad>\", \"<s> oh , yeah , you do n't have to call baby , you do n't have to call me , and say you 're sorry </s> <pad> <pad> <pad> <pad> <pad>\"]\n","tensor([[   2, 8995, 2961, 3995, 6826, 5624, 1091, 5624, 2654, 7306, 2352,  188,\n","            3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0],\n","        [   2, 5573, 5685, 6444, 7398, 4904, 5624, 3166, 5624, 8370, 1775, 5901,\n","         2608,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0]])\n","[\"<s> it all worked out , girl , we should 've known </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\", \"<s> you be like `` oh , word , true shit ? '' </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\"]\n"]}]},{"cell_type":"markdown","metadata":{"id":"gsYSVlUXCffT"},"source":["# Encoder"]},{"cell_type":"code","metadata":{"id":"4MFXx9YHCvPd"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# assert device == \"cuda\"  \n","\n","seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OO0L6wsbCgx3"},"source":["from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","\n","class Encoder(nn.Module):\n","  def __init__(self, input_size, hidden_size, dropout=0.):\n","    \"\"\"\n","    Inputs: \n","      - `input_size`: an int representing the RNN input size.\n","      - `hidden_size`: an int representing the RNN hidden size.\n","      - `dropout`: a float representing the dropout rate during training. Note\n","          that for 1-layer RNN this has no effect since dropout only applies to\n","          outputs of intermediate layers.\n","    \"\"\"\n","    super(Encoder, self).__init__()\n","    self.rnn = nn.GRU(input_size, hidden_size, num_layers=1, batch_first=True,\n","                      dropout=dropout, bidirectional=False)\n","\n","  def forward(self, inputs, lengths):\n","    \"\"\"\n","    Inputs:\n","      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n","          representing a batch of padded embedded word vectors of source\n","          sentences.\n","      - `lengths`: a 1d-tensor of shape (batch_size,) representing the sequence\n","          lengths of `inputs`.\n","\n","    Returns:\n","      - `outputs`: a 3d-tensor of shape\n","        (batch_size, max_seq_length, hidden_size).\n","      - `finals`: a 3d-tensor of shape (num_layers, batch_size, hidden_size).\n","      Hint: `outputs` and `finals` are both standard GRU outputs. Check:\n","      https://pytorch.org/docs/stable/nn.html#gru\n","    \"\"\"\n","    # Our variable-length inputs are padded to the same length for batching\n","    # Here we \"pack\" them for computational efficiency (see note below)\n","    packed = pack_padded_sequence(inputs, lengths.cpu(), batch_first=True,\n","                                  enforce_sorted=False)\n","    outputs, finals = self.rnn(packed)\n","    outputs, _ = pad_packed_sequence(outputs, batch_first=True,\n","                                     total_length=32)\n","    return outputs, finals"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k1jVY88MBlqy"},"source":["# Generator"]},{"cell_type":"code","metadata":{"id":"ujCrKWywBd48"},"source":["class Generator(nn.Module):\n","  \"\"\"Define standard linear + softmax generation step.\"\"\"\n","  def __init__(self, hidden_size, vocab_size):\n","    super(Generator, self).__init__()\n","    self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n","\n","  def forward(self, x):\n","    return F.log_softmax(self.proj(x), dim=-1)\n","\n","class GeneratorTransferredSampled(nn.Module):\n","  \"\"\"Define standard linear + softmax generation step.\"\"\"\n","  def __init__(self, hidden_size, vocab_size, src_embed, gamma=0.1):\n","    \"\"\"\n","    Inputs:\n","      - `src_embed`: a 2d-tensor of shape (vocab_size, embed_size )\n","    \"\"\"\n","    super(GeneratorTransferredSampled, self).__init__()\n","    self.proj = nn.Linear(hidden_size, vocab_size, bias=True)\n","    self.gamma = gamma\n","    self.softmax = nn.Softmax(dim = 2)\n","    self.src_embed = src_embed\n","\n","  def embedding(self,x):\n","    return torch.matmul(x,self.src_embed)\n","    \n","  def gumbel_softmax(self,logits, eps=1e-20):\n","    U = torch.rand(logits.shape)\n","    G = -torch.log(-torch.log(U + eps) + eps)\n","    return self.softmax((logits + G) / self.gamma)\n","\n","  def forward(self, x):\n","    logits = self.proj(x)\n","    prob = self.gumbel_softmax(logits)\n","    output = self.embedding(prob)\n","    word  = logits.argmax(dim = 2, keepdim = False)\n","    return output, prob, word\n","\n","class GeneratorTransferredMax(nn.Module):\n","  \"\"\"Define standard linear + softmax generation step.\"\"\"\n","  def __init__(self, hidden_size, vocab_size, embedding_lookup):\n","    super(GeneratorTransferredMax, self).__init__()\n","    self.proj = nn.Linear(hidden_size, vocab_size, bias=True)\n","    self.softmax = nn.Softmax(dim = 2)\n","    self.embedding_lookup = embedding_lookup\n","\n","\n","  def forward(self, x):\n","    logits = self.proj(x)\n","    logits = self.softmax(logits)\n","    word = logits.argmax(dim=2, keepdim = False)\n","    output = self.embedding_lookup(word)\n","    return output, logits, word"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bWDOysomngJJ"},"source":["# Decoder"]},{"cell_type":"code","metadata":{"id":"ksl1ByscBiFF"},"source":["class Decoder(nn.Module):\n","  \"\"\"An RNN decoder + generator with GRU\"\"\"\n","\n","  def __init__(self, input_size, hidden_size, max_len,generator, num_layers = 1, dropout=0.):\n","    \"\"\"\n","      Inputs:\n","        - `input_size` , `hidden_size`, and `dropout` the same as in Encoder.\n","    \"\"\"\n","    super(Decoder, self).__init__()\n","    self.input_size = input_size\n","    self.hidden_size = hidden_size\n","    self.rnn = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True,\n","                      dropout=dropout, bidirectional=False)\n","    self.generator = generator\n","    self.max_len = max_len\n","\n","  def forward_step(self, prev_embed, hidden):\n","    \"\"\"Helper function for forward below:\n","       Perform a single decoder step (1 word).\n","\n","       Inputs:\n","      - `prev_embed`: a 3d-tensor of shape (batch_size, 1, embed_size = vocab_size)\n","          representing the padded embedded word vectors at this step in training\n","      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size) representing\n","          the current hidden state.\n","\n","      Returns:\n","      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size)\n","          representing the current decoder hidden state.\n","      - `output`: a 3d-tensor of shape (batch_size, max_len, vocab_size)\n","          representing the total generated outputs.\n","    \"\"\"\n","\n","    pre_output,hidden =self.rnn(prev_embed,hidden)\n","    return hidden, pre_output\n","\n","  def forward(self, input, encoder_finals,max_len, style, hidden=None):\n","    \"\"\"Unroll the decoder one step at a time.\n","\n","    Inputs:\n","      - `inputs`: a 3d-tensor of shape (batch_size, 1, embed_size)\n","          representing a batch of padded embedded word vectors of SOS . \n","          If size is (batch_size,max_len, embed_size), then it is teacher forcing.\n","      - `encoder_finals`: a 3d-tensor of shape\n","          (num_enc_layers, batch_size, hidden_size) representing the final\n","          encoder hidden states used to initialize the initial decoder hidden\n","          states.\n","      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size) representing\n","          the value to be used to initialize the initial decoder hidden states.\n","          If None, then use `encoder_finals`.\n","      - `max_len`: an int representing the maximum decoding length.\n","      - `style`: TAYLOR_STYLE or DRAKE_STYLE\n","\n","    Returns:\n","      - `hidden`: a 3d-tensor of shape\n","          (num_layers, batch_size, hidden_size) representing the final hidden\n","          state for each element in the batch.\n","      - `outputs`: a 3d-tensor of shape\n","          (batch_size, max_len, hidden_size) representing the raw decoder\n","          outputs (before mapping to a `trg_vocab_size`-dim vector).\n","      - `logits_vectors`: a 3d-tensor of shape\n","          (batch_size, max_len, trg_vocab_size) representing the mapped decoder\n","          outputs.\n","      - `words`: a 3d-tensor of shape\n","          (batch_size, max_len, 1) representing output sentence and\n","          the corresponding word index (can be used for embedding)  \n","    \"\"\"\n","\n","    # Initialize decoder hidden state.\n","    if hidden is None:\n","      hidden = self.init_hidden(encoder_finals)\n","    output_vectors = []\n","    logits_vectors = []\n","    words = []\n","    for i in range(max_len) :\n","      hidden, prev_output = self.forward_step(input,hidden)\n","      input, logits, output_word = self.generator(prev_output)\n","      styles = torch.full(input.shape,style)\n","\n","      if style == 'target':\n","        input = torch.concat([input,], axis = -1)\n","      else:\n","        input = torch.concat([input,torch.full(input.shape,style)], axis = -1)\n","          \n","      logits_vectors.append(logits)\n","      output_vectors.append(input)\n","      words.append(output_word)\n","    outputs = torch.cat(output_vectors, dim =1)\n","    logits_vectors = torch.cat(logits_vectors,dim = 1)\n","    words = torch.cat(words, axis = -1)\n","    return hidden, outputs ,logits_vectors, words\n","\n","  def forward_teacher(self, input, encoder_finals,max_len=None, hidden=None):\n","    \"\"\"Unroll the decoder one step at a time.\n","\n","    Inputs:\n","      - `inputs`: a 3d-tensor of shape (batch_size,max_len, embed_size)\n","          representing a batch of padded embedded word vectors of original \n","          sentence and acts as  teacher forcing.\n","\n","    Returns:\n","      - `hidden`: a 3d-tensor of shape\n","          (num_layers, batch_size, hidden_size) representing the final hidden\n","          state for each element in the batch.\n","      - `outputs`: a 3d-tensor of shape\n","          (batch_size, max_len, hidden_size) representing the raw decoder\n","          outputs (before mapping to a `trg_vocab_size`-dim vector).\n","      - `logits_vectors`: a 3d-tensor of shape\n","          (batch_size, max_len, trg_vocab_size) representing the mapped decoder\n","          outputs each represents the probability? \n","      - `words`: a 3d-tensor of shape\n","          (batch_size, max_len, 1) representing output sentence and\n","          the corresponding word index (can be used for embedding)      \n","    \"\"\"\n","\n","    # Initialize decoder hidden state.\n","    if max_len is None:\n","      max_len = input.shape[1]\n","    if hidden is None:\n","      hidden = self.init_hidden(encoder_finals)\n","    output_vectors = []\n","    logits_vectors = []\n","    words = []\n","    for i in range(max_len) :\n","      hidden, prev_output = self.forward_step(input[:,i:i+1,:],hidden)\n","      output, logits , output_word= self.generator(prev_output)\n","      logits_vectors.append(logits)\n","      output_vectors.append(output)\n","      words.append(output_word)\n","    outputs = torch.cat(output_vectors, dim =1)\n","    logits_vectors = torch.cat(logits_vectors,dim = 1)\n","    words = torch.cat(words, axis = -1)\n","    return hidden, outputs ,logits_vectors, words\n","\n","  def init_hidden(self, encoder_finals):\n","    \"\"\"Use encoder final hidden state to initialize decoder's first hidden\n","       state.\n","\n","       Input: `encoder_finals` is same as in forward()\n","\n","       Returns: \n","         - `decoder_init_hiddens`: a 3d-tensor of shape \n","              (num_layers, batch_size, hidden_size) representing the initial\n","              hidden state of the decoder for each element in the batch \n","    \"\"\"\n","    decoder_init_hiddens=encoder_finals\n","    return decoder_init_hiddens"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7yVlY9wOD5aC"},"source":["# Combine Model"]},{"cell_type":"code","metadata":{"id":"6swZbwo4aMwn"},"source":["embed_size = 256   # Each word will be represented as a `embed_size`-dim vector.\n","hidden_size = 128  # RNN hidden size.\n","dropout = 0.2\n","vocab_size = len(vocab)\n","max_len = 32\n","embed = nn.Embedding(vocab_size, embed_size)\n","encoder=Encoder(embed_size, hidden_size, dropout=dropout)\n","\n","generator = GeneratorTransferredSampled(hidden_size,vocab_size, embed.weight)\n","decoder=Decoder(embed_size*2, hidden_size,max_len= vocab_size, generator = generator,dropout=dropout)\n","DRAKE_STYLE = 0\n","TAYLOR_STYLE = 1\n","loss = nn.CrossEntropyLoss()\n","for i, (src_ids_taylor, src_lengths_taylor, trg_ids_drake, trg_lengths_drake ) in enumerate(data_loader):\n","  encoder_finals = encoder(embed(src_ids_taylor),src_lengths_taylor)[1]\n","#  print(encoder_finals.shape)\n","  original = embed(src_ids_taylor)\n","  original = torch.concat([original,torch.full(original.shape, TAYLOR_STYLE)],axis = -1)\n","  target = embed(torch.tensor([[SOS_INDEX],[SOS_INDEX]]))\n","  target = torch.concat([target, torch.full(target.shape, DRAKE_STYLE)], \n","                        axis = -1)\n","  decode_original = decoder.forward_teacher(original, \n","                                            encoder_finals)\n","  decode_target = decoder.forward(target, encoder_finals, \n","                                  max_len, style = DRAKE_STYLE)\n","  \n","  loss_rec = loss(F.one_hot(src_ids_taylor, vocab_size).to(torch.float),decode_original[-2])\n","  break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZYbMWrA3qp2N","executionInfo":{"status":"ok","timestamp":1636734572192,"user_tz":300,"elapsed":143,"user":{"displayName":"esc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguJV8bjc8KXweJbVFlXaek04XFMDA6xySQJrubPg=s64","userId":"10970071143705357180"}},"outputId":"49184f95-6183-458c-d9b0-c07f152342b8"},"source":["decode_target[3].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 32])"]},"metadata":{},"execution_count":105}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HQYu-7PI_Ffv","executionInfo":{"status":"ok","timestamp":1636734697320,"user_tz":300,"elapsed":118,"user":{"displayName":"esc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguJV8bjc8KXweJbVFlXaek04XFMDA6xySQJrubPg=s64","userId":"10970071143705357180"}},"outputId":"8a694017-fd83-42bb-f932-6e34b9c653ae"},"source":["decode_original[3].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 32])"]},"metadata":{},"execution_count":115}]},{"cell_type":"code","metadata":{"id":"_BvJbpHSrn4K"},"source":["# taylor -> drake : self-feeding (forward function)\n","# taylot -> taylor : taylot_sent"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3HOErYqUvCw1"},"source":["# Classifier"]},{"cell_type":"code","metadata":{"id":"xJnqRDQbxXpC"},"source":["# embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IyUyoYg2vEcG"},"source":["#Run this cell if using LSTM Classifier\n","\n","LSTMlayers = 3\n","\n","lstm = nn.LSTM(input_size=256, hidden_size=256, num_layers=LSTMlayers, batch_first=True)\n","dropout = nn.Dropout(0.5)\n","fc1 =  nn.Linear(in_features=256, out_features=257)\n","fc2 = nn.Linear(257, 1)\n","\n","#LSTM_forward\n","seq = embed(decode_target[-1])\n","output, (hidden,cell) = lstm(seq)\n","output = dropout(output)\n","output = fc1(output[:,-1])\n","output = F.relu(output)\n","output = fc2(output)\n","output = torch.sigmoid(output)\n","\n","output = output.reshape(output.size(1), -1)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LSW295zq5rBD","executionInfo":{"status":"ok","timestamp":1636734528690,"user_tz":300,"elapsed":133,"user":{"displayName":"esc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguJV8bjc8KXweJbVFlXaek04XFMDA6xySQJrubPg=s64","userId":"10970071143705357180"}},"outputId":"117975f1-7e1b-4a0a-dec2-a9b9fe70d90f"},"source":["output"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.4921, 0.4918]], grad_fn=<ReshapeAliasBackward0>)"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","metadata":{"id":"riyKM-7ZvNbW"},"source":["#Run this cell if using CNN Classifier\n","\n","filter_size = [2,3,4]\n","n_filters = [100,100,100]\n","n_class = 2\n","fc = nn.Linear(np.sum(n_filters), 1)\n","dropout = nn.Dropout(0.5)\n","\n","#CNN_forward:\n","\n","seq = embed(decode_target[-1])\n","seq_reshaped = seq.permute(0,2,1)\n","conv_list = []\n","pool_list = []\n","for convolution1d in nn.ModuleList([nn.Conv1d(256, n_filters[i],filter_size[i]) for i in range(3)]):\n","  conv_list.append(F.relu(convolution1d(seq_reshaped)))\n","      \n","for conv in conv_list:\n","  pool_list.append(F.max_pool1d(conv, conv.shape[2]))\n","      \n","concat = []\n","for pool in pool_list:\n","  concat.append(pool.squeeze(dim=2))      \n","concat = torch.cat(concat, dim=1)\n","\n","output = fc(concat)\n","output = dropout(output)\n","output = torch.sigmoid(output)\n","\n","  # return logits\n","output = output.reshape(output.size(1), -1)\n","      # output looks like : tensor([[0.9315, 0.5000]], grad_fn=<ViewBackward>)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0c2j4FL5E28","executionInfo":{"status":"ok","timestamp":1636733050539,"user_tz":300,"elapsed":345,"user":{"displayName":"esc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguJV8bjc8KXweJbVFlXaek04XFMDA6xySQJrubPg=s64","userId":"10970071143705357180"}},"outputId":"8385f834-abd5-42c1-c7c7-0b959cde545b"},"source":["output"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.7454, 0.5000]], grad_fn=<ReshapeAliasBackward0>)"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"DtdnMitdvQRV"},"source":["# taylor_batch = LSTM_forward(output from decoder)\n","# taylor_batch = CNN_forward(output from decoder)\n","\n","def loss_fcn(taylor_batch, drake_batch): \n","  target_taylor =torch.tensor([[1,1]])\n","  target_drake =torch.tensor([[0,0]])   \n","  target_taylor=target_taylor.type(torch.FloatTensor)\n","  target_drake=target_drake.type(torch.FloatTensor)\n","\n","  #define and add optimizer\n","  taylor_loss = F.binary_cross_entropy(taylor_batch,target_taylor)\n","  drake_loss = F.binary_cross_entropy(drake_batch,target_drake)\n","  return taylor_loss, drake_loss\n","\n","# loss += loss_fcn[0] + loss_fcn[1]"],"execution_count":null,"outputs":[]}]}