{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"encoder & Transformer","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5ZyXl4eSkCfE","executionInfo":{"status":"ok","timestamp":1638404866815,"user_tz":300,"elapsed":6562,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","assert device == \"cuda\"   # use gpu whenever you can!\n","\n","seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"tX9Fz2ZhkE3r","executionInfo":{"status":"ok","timestamp":1638404866815,"user_tz":300,"elapsed":3,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}}},"source":["from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","\n","class Encoder(nn.Module):\n","  def __init__(self, input_size, hidden_size, dropout=0.):\n","    \"\"\"\n","    Inputs: \n","      - `input_size`: an int representing the RNN input size.\n","      - `hidden_size`: an int representing the RNN hidden size.\n","      - `dropout`: a float representing the dropout rate during training. Note\n","          that for 1-layer RNN this has no effect since dropout only applies to\n","          outputs of intermediate layers.\n","    \"\"\"\n","    super(Encoder, self).__init__()\n","    self.rnn = nn.GRU(input_size, hidden_size, num_layers=1, batch_first=True,\n","                      dropout=dropout, bidirectional=False)\n","\n","  def forward(self, inputs, lengths):\n","    \"\"\"\n","    Inputs:\n","      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n","          representing a batch of padded embedded word vectors of source\n","          sentences.\n","      - `lengths`: a 1d-tensor of shape (batch_size,) representing the sequence\n","          lengths of `inputs`.\n","\n","    Returns:\n","      - `outputs`: a 3d-tensor of shape\n","        (batch_size, max_seq_length, hidden_size).\n","      - `finals`: a 3d-tensor of shape (num_layers, batch_size, hidden_size).\n","      Hint: `outputs` and `finals` are both standard GRU outputs. Check:\n","      https://pytorch.org/docs/stable/nn.html#gru\n","    \"\"\"\n","    # Our variable-length inputs are padded to the same length for batching\n","    # Here we \"pack\" them for computational efficiency (see note below)\n","    packed = pack_padded_sequence(inputs, lengths.cpu(), batch_first=True,\n","                                  enforce_sorted=False)\n","    outputs, finals = self.rnn(packed)\n","    outputs, _ = pad_packed_sequence(outputs, batch_first=True,\n","                                     total_length=32)\n","    return outputs, finals"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6wSVd_0dosjc"},"source":[""]},{"cell_type":"code","metadata":{"id":"hMlRWMR7MwIs","executionInfo":{"status":"ok","timestamp":1638404866816,"user_tz":300,"elapsed":3,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}}},"source":["import math\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as Data\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"3D4VdAh4X9Jj","executionInfo":{"status":"ok","timestamp":1638404869215,"user_tz":300,"elapsed":242,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}}},"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        '''\n","        x: [seq_len, batch_size, d_model]\n","        '''\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)\n","\n","def get_attn_pad_mask(seq_q, seq_k):\n","    '''\n","    seq_q: [batch_size, seq_len]\n","    seq_k: [batch_size, seq_len]\n","    seq_len could be src_len or it could be tgt_len\n","    seq_len in seq_q and seq_len in seq_k maybe not equal\n","    '''\n","    batch_size, len_q = seq_q.size()\n","    batch_size, len_k = seq_k.size()\n","    # eq(zero) is PAD token\n","    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # [batch_size, 1, len_k], False is masked\n","    return pad_attn_mask.expand(batch_size, len_q, len_k)  # [batch_size, len_q, len_k]\n","\n","def get_attn_subsequence_mask(seq):\n","    '''\n","    seq: [batch_size, tgt_len]\n","    '''\n","    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n","    subsequence_mask = np.triu(np.ones(attn_shape), k=1) # Upper triangular matrix\n","    subsequence_mask = torch.from_numpy(subsequence_mask).byte()\n","    return subsequence_mask # [batch_size, tgt_len, tgt_len]"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Or9TgFxiX_HQ","executionInfo":{"status":"ok","timestamp":1638404870794,"user_tz":300,"elapsed":412,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}}},"source":["class ScaledDotProductAttention(nn.Module):\n","    def __init__(self):\n","        super(ScaledDotProductAttention, self).__init__()\n","\n","    def forward(self, Q, K, V, attn_mask):\n","        '''\n","        Q: [batch_size, n_heads, len_q, d_k]\n","        K: [batch_size, n_heads, len_k, d_k]\n","        V: [batch_size, n_heads, len_v(=len_k), d_v]\n","        attn_mask: [batch_size, n_heads, seq_len, seq_len]\n","        '''\n","        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size, n_heads, len_q, len_k]\n","        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is True.\n","        \n","        attn = nn.Softmax(dim=-1)(scores)\n","        context = torch.matmul(attn, V) # [batch_size, n_heads, len_q, d_v]\n","        return context, attn\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self):\n","        super(MultiHeadAttention, self).__init__()\n","        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)\n","        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n","        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n","        self.fc = nn.Linear(n_heads * d_v, d_model, bias=False)\n","    def forward(self, input_Q, input_K, input_V, attn_mask):\n","        '''\n","        input_Q: [batch_size, len_q, d_model]\n","        input_K: [batch_size, len_k, d_model]\n","        input_V: [batch_size, len_v(=len_k), d_model]\n","        attn_mask: [batch_size, seq_len, seq_len]\n","        '''\n","        residual, batch_size = input_Q, input_Q.size(0)\n","        # (B, S, D) -proj-> (B, S, D_new) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n","        Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # Q: [batch_size, n_heads, len_q, d_k]\n","        K = self.W_K(input_K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # K: [batch_size, n_heads, len_k, d_k]\n","        V = self.W_V(input_V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  # V: [batch_size, n_heads, len_v(=len_k), d_v]\n","\n","        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # attn_mask : [batch_size, n_heads, seq_len, seq_len]\n","\n","        # context: [batch_size, n_heads, len_q, d_v], attn: [batch_size, n_heads, len_q, len_k]\n","        context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)\n","        context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v) # context: [batch_size, len_q, n_heads * d_v]\n","        output = self.fc(context) # [batch_size, len_q, d_model]\n","        return nn.LayerNorm(d_model).cuda()(output + residual), attn\n","\n","class PoswiseFeedForwardNet(nn.Module):\n","    def __init__(self):\n","        super(PoswiseFeedForwardNet, self).__init__()\n","        self.fc = nn.Sequential(\n","            nn.Linear(d_model, d_ff, bias=False),\n","            nn.ReLU(),\n","            nn.Linear(d_ff, d_model, bias=False)\n","        )\n","    def forward(self, inputs):\n","        '''\n","        inputs: [batch_size, seq_len, d_model]\n","        '''\n","        residual = inputs\n","        output = self.fc(inputs)\n","        return nn.LayerNorm(d_model).cuda()(output + residual) # [batch_size, seq_len, d_model]\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self):\n","        super(EncoderLayer, self).__init__()\n","        self.enc_self_attn = MultiHeadAttention()\n","        self.pos_ffn = PoswiseFeedForwardNet()\n","\n","    def forward(self, enc_inputs, enc_self_attn_mask):\n","        '''\n","        enc_inputs: [batch_size, src_len, d_model]\n","        enc_self_attn_mask: [batch_size, src_len, src_len]\n","        '''\n","        # enc_outputs: [batch_size, src_len, d_model], attn: [batch_size, n_heads, src_len, src_len]\n","        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n","        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size, src_len, d_model]\n","        return enc_outputs, attn\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self):\n","        super(DecoderLayer, self).__init__()\n","        self.dec_self_attn = MultiHeadAttention()\n","        self.dec_enc_attn = MultiHeadAttention()\n","        self.pos_ffn = PoswiseFeedForwardNet()\n","\n","    def forward(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n","        '''\n","        dec_inputs: [batch_size, tgt_len, d_model]\n","        enc_outputs: [batch_size, src_len, d_model]\n","        dec_self_attn_mask: [batch_size, tgt_len, tgt_len]\n","        dec_enc_attn_mask: [batch_size, tgt_len, src_len]\n","        '''\n","        # dec_outputs: [batch_size, tgt_len, d_model], dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len]\n","        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n","        # dec_outputs: [batch_size, tgt_len, d_model], dec_enc_attn: [batch_size, h_heads, tgt_len, src_len]\n","        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n","        dec_outputs = self.pos_ffn(dec_outputs) # [batch_size, tgt_len, d_model]\n","        return dec_outputs, dec_self_attn, dec_enc_attn\n","\n","class Encoder(nn.Module):\n","    def __init__(self):\n","        super(Encoder, self).__init__()\n","        self.src_emb = nn.Embedding(src_vocab_size, d_model)\n","        self.pos_emb = PositionalEncoding(d_model)\n","        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n","\n","    def forward(self, enc_inputs):\n","        '''\n","        enc_inputs: [batch_size, src_len]\n","        '''\n","        enc_outputs = self.src_emb(enc_inputs) # [batch_size, src_len, d_model]\n","        enc_outputs = self.pos_emb(enc_outputs.transpose(0, 1)).transpose(0, 1) # [batch_size, src_len, d_model]\n","        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs) # [batch_size, src_len, src_len]\n","        enc_self_attns = []\n","        for layer in self.layers:\n","            # enc_outputs: [batch_size, src_len, d_model], enc_self_attn: [batch_size, n_heads, src_len, src_len]\n","            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n","            enc_self_attns.append(enc_self_attn)\n","        return enc_outputs, enc_self_attns\n","\n","class Decoder(nn.Module):\n","    def __init__(self):\n","        super(Decoder, self).__init__()\n","        self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n","        self.pos_emb = PositionalEncoding(d_model)\n","        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n","\n","    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n","        '''\n","        dec_inputs: [batch_size, tgt_len]\n","        enc_intpus: [batch_size, src_len]\n","        enc_outputs: [batsh_size, src_len, d_model]\n","        '''\n","        dec_outputs = self.tgt_emb(dec_inputs) # [batch_size, tgt_len, d_model]\n","        dec_outputs = self.pos_emb(dec_outputs.transpose(0, 1)).transpose(0, 1).cuda() # [batch_size, tgt_len, d_model]\n","        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs).cuda() # [batch_size, tgt_len, tgt_len]\n","        dec_self_attn_subsequence_mask = get_attn_subsequence_mask(dec_inputs).cuda() # [batch_size, tgt_len, tgt_len]\n","        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequence_mask), 0).cuda() # [batch_size, tgt_len, tgt_len]\n","\n","        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs) # [batc_size, tgt_len, src_len]\n","\n","        dec_self_attns, dec_enc_attns = [], []\n","        for layer in self.layers:\n","            # dec_outputs: [batch_size, tgt_len, d_model], dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn: [batch_size, h_heads, tgt_len, src_len]\n","            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n","            dec_self_attns.append(dec_self_attn)\n","            dec_enc_attns.append(dec_enc_attn)\n","        return dec_outputs, dec_self_attns, dec_enc_attns\n","\n","class Transformer(nn.Module):\n","    def __init__(self):\n","        super(Transformer, self).__init__()\n","        self.encoder = Encoder().cuda()\n","        self.decoder = Decoder().cuda()\n","        self.projection = nn.Linear(d_model, tgt_vocab_size, bias=False).cuda()\n","    def forward(self, enc_inputs, dec_inputs):\n","        '''\n","        enc_inputs: [batch_size, src_len]\n","        dec_inputs: [batch_size, tgt_len]\n","        '''\n","        # tensor to store decoder outputs\n","        # outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n","        \n","        # enc_outputs: [batch_size, src_len, d_model], enc_self_attns: [n_layers, batch_size, n_heads, src_len, src_len]\n","        enc_outputs, enc_self_attns = self.encoder(enc_inputs)\n","        # dec_outpus: [batch_size, tgt_len, d_model], dec_self_attns: [n_layers, batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn: [n_layers, batch_size, tgt_len, src_len]\n","        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n","        dec_logits = self.projection(dec_outputs) # dec_logits: [batch_size, tgt_len, tgt_vocab_size]\n","        return dec_logits.view(-1, dec_logits.size(-1)), enc_self_attns, dec_self_attns, dec_enc_attns\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJY-2wN5YAxg","executionInfo":{"status":"ok","timestamp":1638404876489,"user_tz":300,"elapsed":4737,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}},"outputId":"dd2a0e2b-7fa7-4724-c1c6-037bc021c2ff"},"source":["!pip install unidecode"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting unidecode\n","  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n","\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 5.5 MB/s \n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.3.2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UY-heqzIYBsC","executionInfo":{"status":"ok","timestamp":1638404878394,"user_tz":300,"elapsed":1908,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}},"outputId":"4682cf3c-bbfa-46df-910b-85ce75d112a0"},"source":["import json\n","import re\n","from unidecode import unidecode\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","import nltk\n","nltk.download('punkt')\n","from collections import Counter"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KH6gdaP2YC6Z","executionInfo":{"status":"ok","timestamp":1638404895588,"user_tz":300,"elapsed":17197,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}},"outputId":"624a6082-1b05-4837-d3dc-e532bc9e53eb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"CRGOtSeGYEQi","executionInfo":{"status":"ok","timestamp":1638404914331,"user_tz":300,"elapsed":18745,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}}},"source":["f = open('/content/drive/Shareddrives/MIT NLP 8.864/Data/drake.json')\n","drake = json.load(f)\n","f.close()\n","\n","f = open('/content/drive/Shareddrives/MIT NLP 8.864/Data/tswift.json')\n","taylor = json.load(f)\n","f.close()\n","\n","drake = [drake['songs'][i]['lyrics'] for i in range(len(drake['songs']))]\n","taylor = [taylor['songs'][i]['lyrics'] for i in range(len(taylor['songs']))]\n","\n","taylor_lyrics = [re.sub('\\u2005', ' ', re.sub(r'[\\(\\[].*?[\\)\\]]', '', taylor[i])).split('\\n') for i in range(len(taylor))]\n","taylor_lyrics = [[unidecode(i) for i in taylor_lyrics[j]] for j in range(len(taylor_lyrics))]\n","taylor_lyrics = [[re.sub('\\d+EmbedShare URLCopyEmbedCopy', '', i) for i in taylor_lyrics[j]] for j in range(len(taylor_lyrics))]\n","taylor_lyrics = [[re.sub('\\d+.EmbedShare URLCopyEmbedCopy', '', i) for i in taylor_lyrics[j]] for j in range(len(taylor_lyrics))]\n","taylor_lyrics = [[re.sub('EmbedShare URLCopyEmbedCopy', '', i) for i in taylor_lyrics[j]] for j in range(len(taylor_lyrics))]\n","taylor_lyrics = [[i for i in taylor_lyrics[j] if i != ''] for j in range(len(taylor_lyrics))]\n","\n","drake_lyrics = [re.sub('\\u2005', ' ', re.sub(r'[\\(\\[].*?[\\)\\]]', '', drake[i])).split('\\n') for i in range(len(drake))]\n","drake_lyrics = [[unidecode(i) for i in drake_lyrics[j]] for j in range(len(drake_lyrics))]\n","drake_lyrics = [[re.sub('\\d+EmbedShare URLCopyEmbedCopy', '', i) for i in drake_lyrics[j]] for j in range(len(drake_lyrics))]\n","drake_lyrics = [[re.sub('\\d+.EmbedShare URLCopyEmbedCopy', '', i) for i in drake_lyrics[j]] for j in range(len(drake_lyrics))]\n","drake_lyrics = [[re.sub('EmbedShare URLCopyEmbedCopy', '', i) for i in drake_lyrics[j]] for j in range(len(drake_lyrics))]\n","drake_lyrics = [[i for i in drake_lyrics[j] if i != ''] for j in range(len(drake_lyrics))]\n","\n","taylor_lyrics = [[line1 + ', ' + line2 for line1,line2 in zip(song[0::2], song[1::2])] for song in taylor_lyrics]\n","taylor_lyrics = [[line1 + ', ' + line2 for line1,line2 in zip(song[0::2], song[1::2])] for song in taylor_lyrics]\n","\n","drake_tokenized = [[word_tokenize(drake_lyrics[i][j]) for j in range(len(drake_lyrics[i]))] for i in range(len(drake_lyrics))]\n","taylor_tokenized = [[word_tokenize(taylor_lyrics[i][j]) for j in range(len(taylor_lyrics[i]))] for i in range(len(taylor_lyrics))]\n","\n","drake_tokenized = [[[word.lower() for word in line] for line in song] for song in drake_tokenized]\n","taylor_tokenized = [[[word.lower() for word in line] for line in song] for song in taylor_tokenized]\n","\n","drake_length = sum([[len(sent) for sent in song] for song in drake_tokenized], [])\n","taylor_length = sum([[len(sent) for sent in song] for song in taylor_tokenized], [])\n","\n","drake_lyrics = sum([[sent for sent in song if (len(sent) >= 10 and len (sent) <= 30)] for song in drake_tokenized], [])\n","taylor_lyrics = sum([[sent for sent in song if (len(sent) >= 10 and len (sent) <= 30)] for song in taylor_tokenized], [])\n","\n","taylor_vocab = sum(taylor_lyrics,[])\n","drake_vocab = sum(drake_lyrics,[])\n","\n","def unique(list1):\n","     \n","    # insert the list to the set\n","    list_set = set(list1)\n","    # convert the set to the list\n","    unique_list = (list(list_set))\n","    return unique_list\n","\n","vocab = taylor_vocab + drake_vocab\n","vocab_counts = Counter(vocab)\n","vocab = unique(vocab)\n","vocab = ['<pad>','<unk>','<s>', '</s>'] + vocab\n","\n","from torch.utils import data\n","import torch\n","\n","# These IDs are reserved.\n","MAX_SENT_LENGTH = 30\n","MAX_SENT_LENGTH_PLUS_SOS_EOS = 32\n","PAD_INDEX = 0\n","UNK_INDEX = 1\n","SOS_INDEX = 2\n","EOS_INDEX = 3\n","RARE_WORD_TRESHOLD = 0\n","\n","vocab_counts['<pad>'] = RARE_WORD_TRESHOLD + 1\n","vocab_counts['<unk>'] = RARE_WORD_TRESHOLD + 1\n","vocab_counts['<s>'] = RARE_WORD_TRESHOLD + 1\n","vocab_counts['</s>'] = RARE_WORD_TRESHOLD + 1\n","\n","class TSTDataset(data.Dataset):\n","    def __init__(self, taylor_sentences, drake_sentences, vocab, vocab_counts, sampling=1.):\n","        self.taylor_sentences = taylor_sentences[:int(len(taylor_sentences) * sampling)]\n","        self.drake_sentences = drake_sentences[:int(len(drake_sentences) * sampling)]\n","\n","        self.max_seq_length = MAX_SENT_LENGTH_PLUS_SOS_EOS\n","        self.vocab = vocab\n","        self.vocab_counts = vocab_counts\n","\n","        self.v2id = {v : i for i, v in enumerate(self.vocab)}\n","        self.id2v = {val : key for key, val in self.v2id.items()}\n","    \n","    def __len__(self):\n","        return min(len(self.taylor_sentences), len(self.drake_sentences))\n","    \n","    def __getitem__(self, index):\n","        taylor_sent = self.taylor_sentences[index]\n","        taylor_len = len(taylor_sent) + 2   # add <s> and </s> to each sentence\n","        taylor_id = []\n","        for w in taylor_sent:\n","            if w not in self.vocab:\n","                w = '<unk>'\n","            if vocab_counts[w] <= RARE_WORD_TRESHOLD:\n","                w = '<unk>'\n","            taylor_id.append(self.v2id[w])\n","\n","        taylor_id = ([SOS_INDEX] + taylor_id + [EOS_INDEX] + [PAD_INDEX] *\n","                  (self.max_seq_length - taylor_len))\n","\n","        drake_sent = self.drake_sentences[index]\n","        drake_len = len(drake_sent) + 2   # add <s> and </s> to each sentence\n","        drake_id = []\n","        for w in drake_sent:\n","            if w not in self.vocab:\n","                w = '<unk>'\n","            if vocab_counts[w] <= RARE_WORD_TRESHOLD:\n","                w = '<unk>'\n","            drake_id.append(self.v2id[w])\n","\n","        drake_id = ([SOS_INDEX] + drake_id + [EOS_INDEX] + [PAD_INDEX] *\n","                  (self.max_seq_length - drake_len))\n","\n","        return torch.tensor(taylor_id), taylor_len, torch.tensor(drake_id), drake_len\n","\n","dataset = TSTDataset(taylor_lyrics, drake_lyrics, vocab, vocab_counts)\n","data_loader = data.DataLoader(dataset, batch_size=2, shuffle=True)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"nB8ynDA0YFmZ","executionInfo":{"status":"error","timestamp":1638404924869,"user_tz":300,"elapsed":10540,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}},"outputId":"e2f2e39f-f8a3-4b22-dab0-4479eb4b2bb8"},"source":["embed_size = 256   # Each word will be represented as a `embed_size`-dim vector.\n","hidden_size = 128  # RNN hidden size.\n","dropout = 0.2\n","vocab_size = len(vocab)\n","max_len = 32\n","\n","src_vocab_size = len(vocab)\n","\n","tgt_vocab_size = len(vocab)\n","\n","src_len = 32\n","tgt_len = 32\n","\n","# Transformer Parameters\n","d_model = 512  # Embedding Size\n","d_ff = 2048 # FeedForward dimension\n","d_k = d_v = 64  # dimension of K(=Q), V\n","n_layers = 6  # number of Encoder of Decoder Layer\n","n_heads = 8  # number of heads in Multi-Head Attention\n","\n","encoder=Encoder().cuda()\n","decoder = Decoder().cuda()\n","projection = nn.Linear(d_model, tgt_vocab_size, bias=False).cuda()\n","for i, (src_ids_taylor, src_lengths_taylor, trg_ids_drake, trg_lengths_drake ) in enumerate(data_loader):\n","  print(src_ids_taylor.shape)\n","  encoder_finals,self_attention_encoder = encoder(src_ids_taylor.cuda())\n","  print(encoder_finals.shape)\n","  dec_outputs, dec_self_attns, dec_enc_attns = decoder(src_ids_taylor.cuda(), src_ids_taylor.cuda(), encoder_finals)\n","  logit_outputs= projection(dec_outputs)\n","  break\n","\n","  "],"execution_count":10,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-f8f29401de05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mn_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m  \u001b[0;31m# number of heads in Multi-Head Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprojection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"oADahG0FYJbI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637696003458,"user_tz":300,"elapsed":14,"user":{"displayName":"Chenwei Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04482025801710927377"}},"outputId":"6d1b1b94-c9ec-41af-a95f-9752fd7ff335"},"source":["print(logit_outputs.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 32, 9328])\n"]}]},{"cell_type":"code","metadata":{"id":"sMzSgSgZ1Zcg"},"source":[""],"execution_count":null,"outputs":[]}]}